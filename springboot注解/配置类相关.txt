【@Configuration】
@Configuration注解在类上，用于定义spring容器(应用上下文，bean的配置类)，可替换xml配置文件(等同于xml配置文件中的<beans>)
被注解的类内部包含有一个或多个被@Bean注解的方法(等同于xml配置文件中的<bean>)
这些方法将会被AnnotationConfigApplicationContext或AnnotationConfigWebApplicationContext类进行扫描，并用于构建bean定义

@Configuration不可以注解final类或者匿名类，对于内部类则必须是静态类

【@Bean】
@Bean注解在返回某个实例的方法上，用以注册bean对象
这个返回实例的方法，内部可以是任何创建对象的方式，如new对象、反射创建对象等等

@Bean默认指定bean的名称为方法同名，默认无初始化和销毁方法调用，默认作用域为singleton(单例)，这些属性可以显式指定

1.默认配置
@Bean
2.指定bean名称、初始化方法名和销毁方法名(位于bean类中的公共无参方法，用以在bean的初始化前和销毁后进行一些方法调用)
@Bean(name = "myBean",initMethod = "initMethodNameInBeanClass",destroyMethod = "destroyMethodNameInBeanClass")
3.指定bean名称、初始化方法名和销毁方法名，并指定作用域
@Bean(name = "myBean",initMethod = "initMethodNameInBeanClass",destroyMethod = "destroyMethodNameInBeanClass")
@Scope(value = "someScope")
作用域的取值有5种
1、singleton，默认配置，单例作用域，一个Spring容器中只有一个Bean的实例，全容器共享一个实例 
2、prototype，原型作用域，每次调用新建一个Bean的实例 
3、request，请求级作用域，Web项目中对每一个http request新建一个Bean实例
4、session，会话级作用域，Web项目中对每一个http session新建一个Bean实例
5、globalsession，这个只在portal应用中有用，给每一个global http session新建一个Bean实例

既然@Bean的作用是注册bean对象，那么完全可以使用@Component、@Controller、@Service、@Ripository等注解注册bean，当然需要配置@ComponentScan注解进行自动扫描。


【示例】
@Configuration
public class TestConfiguration {
	//配置类的构造函数，在spring创建配置类对象时会自动调用，一般不需要显式的无参构造
	public TestConfiguration() {
		System.out.println("TestConfiguration容器启动初始化...");
	}
}

3.@ConfigurationProperties









curl -H 'Content-type:application/json' -XPUT 'http://172.16.49.61:9200/_all/_settings?preserve_existing=true' -d '{"index.max_result_window" : "21000"}'
curl -H 'Content-type:application/json' -XPUT 'http://172.16.49.62:9200/_all/_settings?preserve_existing=true' -d '{"index.max_result_window" : "21000"}'
curl -H 'Content-type:application/json' -XPUT 'http://172.16.49.63:9200/_all/_settings?preserve_existing=true' -d '{"index.max_result_window" : "21000"}'



nohup java -jar -Xms512M -Xmx1024M server1/eureka.jar --spring.profiles.active=local --server.port=16161 > server1/eureka.log &
nohup java -jar -Xms512M -Xmx1024M server2/eureka.jar --spring.profiles.active=dev --server.port=16262 > server2/eureka.log &


nohup java -jar -Xms512M -Xmx1024M server2/eureka.jar --server.port=16262 > server2/eureka.log &


nohup java -jar -Xms512M -Xmx1024M server1/api-gateway.jar --server.port=15151 > server1/api-gateway.log &
nohup java -jar -Xms512M -Xmx1024M server2/api-gateway.jar --server.port=15252 > server2/api-gateway.log &



firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="172.16.27.0/24" port protocol="tcp" port="12301" accept"
firewall-cmd --reload

firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="172.16.0.0/16" port protocol="tcp" port="18181" accept"
firewall-cmd --reload


firewall-cmd --list-all

firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="172.16.49.0/24" port protocol="tcp" port="16161" accept"
firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="172.16.49.0/24" port protocol="tcp" port="16262" accept"
firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="0.0.0.0/0" port protocol="tcp" port="15151" accept"
firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="0.0.0.0/0" port protocol="tcp" port="15252" accept"
firewall-cmd --reload

ALTER TABLE p2p_cloud_user ADD UNIQUE INDEX `access_no`(`access_no`) USING BTREE;

nohup java -jar -Xms512M -Xmx1024M server1/api-gateway.jar --server.port=15151 > server1/api-gateway.log &

nohup java -jar -Xms512M -Xmx3072M cloud-zhzz.jar > cloud-zhzz.log &


解压和重新打jar包


upstream cloudEndP2PUser{
server 172.16.49.44:17171;
server 172.16.49.44:17272;
ip_hash;
}

location /cloudEndP2PUser {
	proxy_pass http://cloudEndP2PUser;
}


172.16.49.57 availability1
172.16.49.57 availability2


upstream api-gateway{
server 172.16.49.57:15151;
server 172.16.49.57:15252;
ip_hash;
}


firewall-cmd --permanent --remove-port=16161/tcp
firewall-cmd --permanent --remove-port=16262/tcp
firewall-cmd --permanent --remove-port=15151/tcp
firewall-cmd --permanent --remove-port=15252/tcp
firewall-cmd --reload


nohup java -jar -Xms128M -Xmx256M server1/cloudEndP2PUser.jar --spring.profiles.active=online --server.port=17161 > server1/cloudEndP2PUser.log &
nohup java -jar -Xms512M -Xmx1024M server2/cloudEndP2PUser.jar --spring.profiles.active=online --server.port=17262 > server2/cloudEndP2PUser.log &

firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="0.0.0.0/0" port protocol="tcp" port="16379" accept"
firewall-cmd --reload


server 172.16.49.57:15151;
server 172.16.49.57:15252;

<table name="p2p_distribute_internet" primaryKey="id" type="global" dataNode="dn1" />
<table name="p2p_zq_user" primaryKey="id" type="global" dataNode="dn1" />


git库迁移
cloud网关完善，其它模块上线


curl -X POST '172.16.49.65:9200/es_ping/_delete_by_query?conflicts=proceed&pretty' \
	-H 'Content-Type: application/json' -d '{"query": {"match_all": {}}}'


curl -X GET '172.16.49.65:9200/_count?pretty'

curl -X GET '172.16.49.65:9200/es_ping/pingdoc/_search?pretty'


mvn install:install-file -DgroupId=org.apache -DartifactId=tomcat-api -Dversion=1.0 -Dpackaging=jar -Dfile=tomcat-api.jar
mvn install:install-file -DgroupId=com.yuqiaotech -DartifactId=estivate -Dversion=2.0_db -Dpackaging=jar -Dfile=yq-estivate-2.0_db.jar
mvn install:install-file -DgroupId=com.yuqiaotech -DartifactId=core -Dversion=2.0 -Dpackaging=jar -Dfile=yqfw-core-2.0.jar


nohup java -jar -Xms128M -Xmx256M test.jar --server.port=1234 > test.log


*****无线网优迁移方案整体概要v1.0*****

【1.应用迁移】整个过程全部使用老数据库，目标：老nginx老应用老数据库-->新nginx新应用老数据库，用户可感知切换
1.1对缺失源码的服务进行源码恢复
1.2新服务器外部接口白名单申请
1.3恢复的源码打包发布到老服务器进行测试，验证基本功能的完整准确性
1.4新服务应用部署
1.5新服务器应用测试(白名单批复后)，验证迁移后网络的连通性
1.6老服务器nginx转发切换到新服务器应用(对用户透明)，验证功能的可用性，分析用户反馈的线上问题
	判断是否因迁移过程中源码不完整、网络不连通等原因导致，并解决此类问题
1.7新服务器nginx部署，验证转发的有效性
1.8通知用户使用新nginx访问服务
1.9分析用户反馈的线上问题，判断是否因新nginx代理接口调用缺失白名单等原因导致，至少观察一星期

【2.数据库迁移】目标：新nginx新应用老数据库-->新nginx新应用新数据库，切换对用户透明
2.1新数据库创建，对新应用服务器开放内部白名单并实测验证网络的连通性
2.2数据迁移可行性测试，验证跨版本跨字符编码的多个数据库数据迁移的可行性，评估迁移时间
//以上操作和应用迁移同步进行
2.3对所有应用服务各备一份配置了新nginx新数据库的安装包等待正式库的迁移
//以上操作在1.3完成之后，并随着1.6、1.9和2.6步骤的进行不断更新应用包
2.4清空新数据库的脏数据，备份所有应用服务安装包，上传新安装包，准备数据正式迁移
2.4.1所有老库新应用服务停机、所有老数据库定时任务关闭
2.4.2数据库正式迁移
2.4.3删除老库新应用包(已备份)，发布新库新应用包，启动应用服务
2.4.4基础功能自测
2.5异常或错误的回滚，当任何一个过程出现问题且短期无法解决时，记录问题，并视情况迅速回滚应用
2.5.1迁移数据库失败：重启所有老数据库定时任务，恢复所有老库新应用服务备份包，重启所有老库新应用服务，应用恢复后进行基础功能自测
2.5.2新库新应用启动或自测失败：关闭所有已经启动(无论成败)的新库新应用服务，记录所有已成功启动的新库新应用服务列表，备份新库新应用服务，恢复老库新应用服务，然后执行2.5.1步骤
2.6迁移失败后，分析和解决目标问题，重复2.3~2.5操作，直到迁移成功
2.7上传最新的代码，此代码认为是功能基本可用、完整的，且可直接用于部署新服务器的
2.8分析用户反馈的线上问题，判断是否因迁移过程中数据库数据不完整等原因导致，至少观察1个月
//以上操作在1.8完成之后












