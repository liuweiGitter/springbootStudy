1.确定版本关系
springboot、spring-kafka、kafka-client三者之间有版本匹配关系要求，具体参见
https://spring.io/projects/spring-kafka

springboot   spring-kafka kafka
2.4.x        3.3.x        2.4.0
2.3.x        3.2.x        2.3.1
2.2.x        3.1.x        2.0.1/2.1.x/2.2.x

实际上三者之间的版本对应关系非常乱，官网只是给出了建议而已，实际可能无法使用

以springboot 2.2版本为例，官网建议
2.2.x uses the 2.0.x kafka-clients by default. When overriding the kafka-clients for 2.2.x see the documentation appendix.
Spring Boot 2.2 users should use 2.3.x (Boot dependency management will use the correct version).
即2.2版本的springboot应使用2.3版本的spring-kafka，并默认支持2.0版本的kafka-clients
如果此时需要支持2.2版本的kafka-clients，需要有额外配置
https://docs.spring.io/spring-kafka/docs/2.2.1.BUILD-SNAPSHOT/reference/html/deps-for-21x.html

下文版本关系为：springboot2.2.2、spring-kafka2.3.4、kafka-clients2.2.0

2.pom配置kafka依赖
根据实际的kafka版本，配置对应的依赖版本(注意，版本不匹配可能造成无法接发消息，甚至都无法启动springboot)
	<parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.2.2.RELEASE</version>
        <relativePath/>
    </parent>
	
	<!-- https://mvnrepository.com/artifact/org.springframework.kafka/spring-kafka -->
	<dependency>
		<groupId>org.springframework.kafka</groupId>
		<artifactId>spring-kafka</artifactId>
		<version>2.3.4.RELEASE</version>
	</dependency>
	
	<dependency>
		<groupId>org.apache.kafka</groupId>
		<artifactId>kafka-clients</artifactId>
		<version>2.2.0</version>
	</dependency>
	
3.application配置文件
	#kafka服务
	#单机spring.kafka.bootstrap-servers=x.x.x.x:19092
	#集群spring.kafka.bootstrap-servers=x.x.x.x:19092,x.x.x.x:19092,x.x.x.x:19092
	#生产者
	spring.kafka.producer.retries=3
	spring.kafka.producer.batch-size=10240
	spring.kafka.producer.buffer-memory=1024000
	spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
	spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
	#消费者
	spring.kafka.consumer.enable-auto-commit=true
	spring.kafka.consumer.auto-commit-interval=1000
	spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
	spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
	#监听
	#监听的主题不存在时，不报错，继续启动，默认停止启动
	spring.kafka.listener.missing-topics-fatal=false
	
	#外部kafka服务
	spring.kafka-outer1.bootstrap-servers=172.16.49.68:9092


4.启动springboot
成功启动后有类似以下信息打印
	00:26:54.042 [RMI TCP Connection(3)-127.0.0.1] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [x.x.x.x:19092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = consumer1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	
	如果有生产者生产消息，正常情况下，消费者测试时控制台可能打印以下信息
	consumer1>>>topic=test1,offset=5,value=nice 
	consumer2>>>topic=test1,offset=5,value=nice

5.kafka错误问题
》5.1连接错误
00:38:13.642 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] 
WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-1, groupId=consumer1] 
Connection to node -1 (/x.x.x.x:19092) could not be established. Broker may not be available.

如果x.x.x.x为外网地址，通常这是由于kafka服务没有绑定外网地址导致的
必须在kafka配置文件中配置advertised.listeners才可以外网访问

》5.2生产者关闭错误
java.lang.NoSuchMethodError: org.apache.kafka.clients.producer.Producer.close(Ljava/time/Duration;)V
这是因为kafka-clients不同的版本中方法不同造成的，所以要严格匹配版本关系
spring-kafka2.3.4版本会调用kafka-client中的这个方法，在低版本中没有这个方法，kafka-client 2.2.0版本有此方法

6.生产者和消费者配置、使用demo、服务中心参见《springboot集成示例》













